{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the provided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"concrete_data.csv\")\n",
    "df_y = df[\"Strength\"]\n",
    "df_X = df.drop([\"Strength\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART A. Build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a single hidden layer of 10 nodes, and a ReLU activation function\n",
    "model.add(Dense(10, input_dim=8, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))  # Output layer for linear regression output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model using Adam optimizer and loss mean_squared_error\n",
    "model.compile(loss=mean_squared_error, optimizer=Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the model on the training data using 50 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=50, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.  Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 797us/step - loss: 104.6404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "104.6403579711914"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer : Acceptable loss on the test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 869us/step - loss: 65.6638\n",
      "10/10 [==============================] - 0s 779us/step - loss: 61.2950\n",
      "10/10 [==============================] - 0s 846us/step - loss: 63.2846\n",
      "10/10 [==============================] - 0s 832us/step - loss: 60.9121\n",
      "10/10 [==============================] - 0s 710us/step - loss: 84.8197\n",
      "10/10 [==============================] - 0s 940us/step - loss: 48.6660\n",
      "10/10 [==============================] - 0s 825us/step - loss: 39.0023\n",
      "10/10 [==============================] - 0s 702us/step - loss: 47.2966\n",
      "10/10 [==============================] - 0s 719us/step - loss: 45.2584\n",
      "10/10 [==============================] - 0s 900us/step - loss: 59.8996\n",
      "10/10 [==============================] - 0s 728us/step - loss: 51.1922\n",
      "10/10 [==============================] - 0s 723us/step - loss: 41.4739\n",
      "10/10 [==============================] - 0s 723us/step - loss: 47.6843\n",
      "10/10 [==============================] - 0s 808us/step - loss: 44.9355\n",
      "10/10 [==============================] - 0s 721us/step - loss: 45.0075\n",
      "10/10 [==============================] - 0s 826us/step - loss: 37.9384\n",
      "10/10 [==============================] - 0s 808us/step - loss: 57.3663\n",
      "10/10 [==============================] - 0s 833us/step - loss: 43.8403\n",
      "10/10 [==============================] - 0s 772us/step - loss: 51.8638\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 49.9678\n",
      "10/10 [==============================] - 0s 912us/step - loss: 41.7152\n",
      "10/10 [==============================] - 0s 2ms/step - loss: 42.9988\n",
      "10/10 [==============================] - 0s 877us/step - loss: 41.2219\n",
      "10/10 [==============================] - 0s 714us/step - loss: 40.2873\n",
      "10/10 [==============================] - 0s 682us/step - loss: 41.9480\n",
      "10/10 [==============================] - 0s 755us/step - loss: 40.3693\n",
      "10/10 [==============================] - 0s 858us/step - loss: 46.4108\n",
      "10/10 [==============================] - 0s 754us/step - loss: 57.7367\n",
      "10/10 [==============================] - 0s 742us/step - loss: 55.4852\n",
      "10/10 [==============================] - 0s 955us/step - loss: 48.1903\n",
      "10/10 [==============================] - 0s 772us/step - loss: 45.4509\n",
      "10/10 [==============================] - 0s 888us/step - loss: 53.5984\n",
      "10/10 [==============================] - 0s 701us/step - loss: 38.3082\n",
      "10/10 [==============================] - 0s 738us/step - loss: 38.6417\n",
      "10/10 [==============================] - 0s 701us/step - loss: 40.6269\n",
      "10/10 [==============================] - 0s 759us/step - loss: 54.9435\n",
      "10/10 [==============================] - 0s 1ms/step - loss: 47.3149\n",
      "10/10 [==============================] - 0s 796us/step - loss: 42.3713\n",
      "10/10 [==============================] - 0s 801us/step - loss: 73.3015\n",
      "10/10 [==============================] - 0s 728us/step - loss: 47.6383\n",
      "10/10 [==============================] - 0s 811us/step - loss: 40.6988\n",
      "10/10 [==============================] - 0s 942us/step - loss: 51.0135\n",
      "10/10 [==============================] - 0s 729us/step - loss: 41.4910\n",
      "10/10 [==============================] - 0s 774us/step - loss: 77.7684\n",
      "10/10 [==============================] - 0s 891us/step - loss: 39.0907\n",
      "10/10 [==============================] - 0s 800us/step - loss: 39.2091\n",
      "10/10 [==============================] - 0s 750us/step - loss: 37.1323\n",
      "10/10 [==============================] - 0s 714us/step - loss: 42.2613\n",
      "10/10 [==============================] - 0s 869us/step - loss: 46.9274\n",
      "10/10 [==============================] - 0s 733us/step - loss: 48.7828\n"
     ]
    }
   ],
   "source": [
    "mean_squared_error_list =  [] # List to hold all the mean_squared_erros\n",
    "\n",
    "for step_number in range(50):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.3)\n",
    "    history = model.fit(X_train, y_train, epochs=50, verbose=0)\n",
    "    step_mean_squared_error = model.evaluate(X_test, y_test)\n",
    "    mean_squared_error_list.append(step_mean_squared_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Report the mean and the standard deviation of the mean squared errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of mean squared errors is :  49.00604789733887\n",
      "Standard Deviation of mean squared errors is :  108.68849624694214\n"
     ]
    }
   ],
   "source": [
    "mean_of_mse = sum(mean_squared_error_list) / len(mean_squared_error_list)\n",
    "standard_deviation_of_mse = sum([((x - mean_of_mse) ** 2) for x in mean_squared_error_list]) / len(mean_squared_error_list)\n",
    "\n",
    "print(\"Mean of mean squared errors is : \",mean_of_mse)\n",
    "print(\"Standard Deviation of mean squared errors is : \", standard_deviation_of_mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
