{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/tmdb-box-office-prediction/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'belongs_to_collection', 'budget', 'genres', 'homepage',\n",
       "       'imdb_id', 'original_language', 'original_title', 'overview',\n",
       "       'popularity', 'poster_path', 'production_companies',\n",
       "       'production_countries', 'release_date', 'runtime', 'spoken_languages',\n",
       "       'status', 'tagline', 'title', 'Keywords', 'cast', 'crew', 'revenue'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3000, 23), (4398, 22))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyse and add other columns accordingly \n",
    "# Remove status and impute others\n",
    "drop_cols = [\"id\", \"belongs_to_collection\", \"homepage\", \"imdb_id\", \"original_title\", \"overview\", \"poster_path\", \"production_companies\", \"spoken_languages\", \"status\", \"Keywords\", \"cast\", \"crew\", \"tagline\", \"title\"]\n",
    "cols_to_drop_after_preprocessing = []\n",
    "len(drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_categories = []\n",
    "categorical_categories = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                3000 non-null   int64  \n",
      " 1   genres                2993 non-null   object \n",
      " 2   original_language     3000 non-null   object \n",
      " 3   popularity            3000 non-null   float64\n",
      " 4   production_countries  2945 non-null   object \n",
      " 5   release_date          3000 non-null   object \n",
      " 6   runtime               2998 non-null   float64\n",
      " 7   revenue               3000 non-null   int64  \n",
      "dtypes: float64(2), int64(2), object(4)\n",
      "memory usage: 187.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4398 entries, 0 to 4397\n",
      "Data columns (total 7 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   budget                4398 non-null   int64  \n",
      " 1   genres                4382 non-null   object \n",
      " 2   original_language     4398 non-null   object \n",
      " 3   popularity            4398 non-null   float64\n",
      " 4   production_countries  4296 non-null   object \n",
      " 5   release_date          4397 non-null   object \n",
      " 6   runtime               4394 non-null   float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 240.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.drop(drop_cols, axis = 1, inplace=True)\n",
    "test_df.drop(drop_cols, axis = 1, inplace=True)\n",
    "train_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 1. Budget : Put mean of budget if budget is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add budget to numerical category\n",
    "numerical_categories.append(\"budget\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use mean budget if budget is empty/0\n",
    "budget_mean_train = train_df[train_df.budget != 0].budget.mean()\n",
    "train_df.budget = train_df.budget.apply(lambda x : budget_mean_train if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the same for test data\n",
    "budget_mean_test = test_df[test_df.budget != 0].budget.mean()\n",
    "test_df.budget = test_df.budget.apply(lambda x : budget_mean_test if x == 0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 2. Genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add genres_list to categorical_category\n",
    "categorical_categories.append(\"genres_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of genres instead of the string\n",
    "\n",
    "def get_genres(genres_string):\n",
    "    \"\"\"Returns tuple of genres generated from the passed genres string\"\"\"\n",
    "    all_genres = []\n",
    "    if pd.isna(genres_string):\n",
    "        return []\n",
    "#     print(f\"processing {type(genres_string)}\")\n",
    "    for genre in json.loads(genres_string.replace(\"'\", \"\\\"\")):\n",
    "        all_genres.append(genre.get(\"name\"))\n",
    "    return tuple(all_genres)\n",
    "\n",
    "train_df[\"genres_list\"] = train_df.genres.apply(lambda x : get_genres(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same operation on test dataframe\n",
    "test_df[\"genres_list\"] = test_df.genres.apply(lambda x : get_genres(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a complete list of all the possible genres\n",
    "all_genres_set = set()\n",
    "for genres_list in train_df.genres_list:\n",
    "    for genre in genres_list:\n",
    "        all_genres_set.add(genre)\n",
    "\n",
    "for genres_list in test_df.genres_list:\n",
    "    for genre in genres_list:\n",
    "        all_genres_set.add(genre)\n",
    "        \n",
    "# all_genres_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_after_preprocessing.append(\"genres\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 3. Original_language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add original_language to categorical_category\n",
    "categorical_categories.append(\"original_language\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No empty language, so proceed\n",
    "train_df.original_language.isna().any(), test_df.original_language.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 4. Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add popularity to numerical_category\n",
    "numerical_categories.append(\"popularity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# No empty popularity, so proceed\n",
    "train_df.popularity.isna().any(), test_df.popularity.isna().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 5. production_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add production_countries_list to categorical_category\n",
    "categorical_categories.append(\"production_countries_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from ast import literal_eval\n",
    "# Creat complete list of the possible genres and then one hot encode it\n",
    "def get_production_countries(production_string):\n",
    "    all_production_countries = []\n",
    "    if pd.isna(production_string):\n",
    "        return []\n",
    "    for country in literal_eval(production_string):\n",
    "        all_production_countries.append(country.get(\"iso_3166_1\"))\n",
    "    return tuple(all_production_countries)\n",
    "\n",
    "train_df[\"production_countries_list\"] = train_df.production_countries.apply(lambda x : get_production_countries(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"production_countries_list\"] = test_df.production_countries.apply(lambda x : get_production_countries(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AE',\n",
       " 'AF',\n",
       " 'AO',\n",
       " 'AR',\n",
       " 'AT',\n",
       " 'AU',\n",
       " 'BA',\n",
       " 'BE',\n",
       " 'BF',\n",
       " 'BG',\n",
       " 'BO',\n",
       " 'BR',\n",
       " 'BS',\n",
       " 'BW',\n",
       " 'CA',\n",
       " 'CD',\n",
       " 'CH',\n",
       " 'CI',\n",
       " 'CL',\n",
       " 'CM',\n",
       " 'CN',\n",
       " 'CO',\n",
       " 'CR',\n",
       " 'CS',\n",
       " 'CY',\n",
       " 'CZ',\n",
       " 'DE',\n",
       " 'DK',\n",
       " 'DO',\n",
       " 'DZ',\n",
       " 'EC',\n",
       " 'ES',\n",
       " 'ET',\n",
       " 'FI',\n",
       " 'FR',\n",
       " 'GB',\n",
       " 'GE',\n",
       " 'GH',\n",
       " 'GR',\n",
       " 'HK',\n",
       " 'HR',\n",
       " 'HU',\n",
       " 'ID',\n",
       " 'IE',\n",
       " 'IL',\n",
       " 'IN',\n",
       " 'IR',\n",
       " 'IS',\n",
       " 'IT',\n",
       " 'JM',\n",
       " 'JO',\n",
       " 'JP',\n",
       " 'KH',\n",
       " 'KR',\n",
       " 'KZ',\n",
       " 'LI',\n",
       " 'LK',\n",
       " 'LT',\n",
       " 'LU',\n",
       " 'MA',\n",
       " 'MC',\n",
       " 'MK',\n",
       " 'ML',\n",
       " 'MN',\n",
       " 'MR',\n",
       " 'MT',\n",
       " 'MX',\n",
       " 'MY',\n",
       " 'NA',\n",
       " 'NL',\n",
       " 'NO',\n",
       " 'NZ',\n",
       " 'PE',\n",
       " 'PH',\n",
       " 'PK',\n",
       " 'PL',\n",
       " 'PR',\n",
       " 'PS',\n",
       " 'PT',\n",
       " 'PY',\n",
       " 'QA',\n",
       " 'RO',\n",
       " 'RS',\n",
       " 'RU',\n",
       " 'SA',\n",
       " 'SE',\n",
       " 'SG',\n",
       " 'SI',\n",
       " 'SN',\n",
       " 'TH',\n",
       " 'TN',\n",
       " 'TR',\n",
       " 'TW',\n",
       " 'UA',\n",
       " 'US',\n",
       " 'UY',\n",
       " 'VE',\n",
       " 'ZA'}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a complete list of all the possible production countries\n",
    "all_production_countries_set = set()\n",
    "for production_countries_list in train_df.production_countries_list:\n",
    "    for country in production_countries_list:\n",
    "        all_production_countries_set.add(country)\n",
    "        \n",
    "for production_countries_list in test_df.production_countries_list:\n",
    "    for country in production_countries_list:\n",
    "        all_production_countries_set.add(country)\n",
    "all_production_countries_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_after_preprocessing.append(\"production_countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 5. Release date needs to be converted to age feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add age to numerical category\n",
    "numerical_categories.append(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "train_df[\"age\"] = train_df.release_date.apply(lambda x : datetime.now().year - datetime.strptime(x, '%m/%d/%y').year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the same on test dataframe\n",
    "test_df[\"age\"] = test_df.release_date.apply(lambda x : datetime.now().year - datetime.strptime(x, '%m/%d/%y').year if pd.isna(x) is False else train_df.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop_after_preprocessing.append(\"release_date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature 6. Add runtime to numerical categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_categories.append(\"runtime\")\n",
    "train_df_runtime_mean = train_df.runtime.mean()\n",
    "train_df.runtime.fillna(value=train_df_runtime_mean, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop the columns not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(cols_to_drop_after_preprocessing, axis=1, inplace=True)\n",
    "test_df.drop(cols_to_drop_after_preprocessing, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 8 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   budget                     3000 non-null   float64\n",
      " 1   original_language          3000 non-null   object \n",
      " 2   popularity                 3000 non-null   float64\n",
      " 3   runtime                    3000 non-null   float64\n",
      " 4   revenue                    3000 non-null   int64  \n",
      " 5   genres_list                3000 non-null   object \n",
      " 6   production_countries_list  3000 non-null   object \n",
      " 7   age                        3000 non-null   int64  \n",
      "dtypes: float64(3), int64(2), object(3)\n",
      "memory usage: 187.6+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4398 entries, 0 to 4397\n",
      "Data columns (total 7 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   budget                     4398 non-null   float64\n",
      " 1   original_language          4398 non-null   object \n",
      " 2   popularity                 4398 non-null   float64\n",
      " 3   runtime                    4394 non-null   float64\n",
      " 4   genres_list                4398 non-null   object \n",
      " 5   production_countries_list  4398 non-null   object \n",
      " 6   age                        4398 non-null   float64\n",
      "dtypes: float64(4), object(3)\n",
      "memory usage: 240.6+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.info(), test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['genres_list', 'original_language', 'production_countries_list'],\n",
       " ['budget', 'popularity', 'age', 'runtime'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_categories, numerical_categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a pipeline to scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the numerical categories\n",
    "train_numerical_df = pd.DataFrame(data = scaler.fit_transform(train_df[numerical_categories]), columns=numerical_categories)\n",
    "test_numerical_df = pd.DataFrame(data = scaler.fit_transform(test_df[numerical_categories]), columns=numerical_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encode the categorical categories\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_df(df):\n",
    "    combined_categorical_df = pd.DataFrame()\n",
    "    for category in categorical_categories:\n",
    "        multilabelbinarizer = MultiLabelBinarizer()\n",
    "        data = multilabelbinarizer.fit_transform(df[category])\n",
    "        columns = multilabelbinarizer.classes_\n",
    "        new_df = pd.DataFrame(data, columns=columns)\n",
    "        combined_categorical_df = pd.concat([combined_categorical_df, new_df], axis=1)\n",
    "    return combined_categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_df = get_categorical_df(train_df)\n",
    "test_categorical_df = get_categorical_df(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine Numerical and Categorical Dataframes to form a single unique dataframe\n",
    "train_final_df = pd.concat([train_numerical_df, train_categorical_df, train_df[\"revenue\"]], axis=1)\n",
    "test_final_df = pd.concat([test_numerical_df, test_categorical_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 104) (4398, 103)\n"
     ]
    }
   ],
   "source": [
    "# Remove cols not present in both\n",
    "drop_from_train = list(set(train_final_df.columns) - set(test_final_df.columns))\n",
    "drop_from_test = list(set(test_final_df.columns) - set(train_final_df.columns))\n",
    "\n",
    "drop_from_train.remove(\"revenue\")\n",
    "\n",
    "train_final_df.drop(drop_from_train, axis=1, inplace=True)\n",
    "test_final_df.drop(drop_from_test, axis=1, inplace=True)\n",
    "\n",
    "print(train_final_df.shape, test_final_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_final_df.drop(\"revenue\", axis=1, inplace=False), train_final_df[\"revenue\"], test_size=0.2, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 104)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a keras model for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "budget        False\n",
       "popularity    False\n",
       "age           False\n",
       "runtime       False\n",
       "Action        False\n",
       "              ...  \n",
       "TW            False\n",
       "UA            False\n",
       "US            False\n",
       "ZA            False\n",
       "revenue       False\n",
       "Length: 104, dtype: bool"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final_df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a keras model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_dim=len(X_train.columns), activation=\"relu\"))\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "# opt = SGD(lr=0.01, momentum=0.9)\n",
    "model.compile(loss='mean_squared_logarithmic_error', optimizer=RMSprop(learning_rate=0.001), metrics=[\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 4.2240 - mse: 10489183088934912.0000 - val_loss: 4.9690 - val_mse: 8368648750104576.0000\n",
      "Epoch 2/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 4.0936 - mse: 9335000822448128.0000 - val_loss: 5.0165 - val_mse: 6958038682435584.0000\n",
      "Epoch 3/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 3.9268 - mse: 9585722759577600.0000 - val_loss: 4.9603 - val_mse: 7450339645063168.0000\n",
      "Epoch 4/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 3.7967 - mse: 8568711011106816.0000 - val_loss: 5.5948 - val_mse: 6591536238166016.0000\n",
      "Epoch 5/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 3.7538 - mse: 8288097712209920.0000 - val_loss: 5.5392 - val_mse: 8731789845594112.0000\n",
      "Epoch 6/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 3.6428 - mse: 8906136526782464.0000 - val_loss: 5.8503 - val_mse: 7496642613739520.0000\n",
      "Epoch 7/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.5998 - mse: 8700178886295552.0000 - val_loss: 6.9615 - val_mse: 8210957415219200.0000\n",
      "Epoch 8/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.4442 - mse: 10358507635212288.0000 - val_loss: 5.3736 - val_mse: 6756685246889984.0000\n",
      "Epoch 9/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.3919 - mse: 9972380411625472.0000 - val_loss: 5.6227 - val_mse: 7070977531838464.0000\n",
      "Epoch 10/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.2978 - mse: 9439430804766720.0000 - val_loss: 5.3786 - val_mse: 6252011557224448.0000\n",
      "Epoch 11/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.2685 - mse: 8959228228141056.0000 - val_loss: 5.5384 - val_mse: 6154332189753344.0000\n",
      "Epoch 12/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 3.0977 - mse: 8572424010334208.0000 - val_loss: 5.5823 - val_mse: 6913202981961728.0000\n",
      "Epoch 13/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 3.1321 - mse: 8641448429748224.0000 - val_loss: 5.5000 - val_mse: 6246344347877376.0000\n",
      "Epoch 14/100\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.9848 - mse: 9711758574878720.0000 - val_loss: 5.3407 - val_mse: 6392686768553984.0000\n",
      "Epoch 15/100\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 2.8697 - mse: 8774015816564736.0000 - val_loss: 5.9256 - val_mse: 7110999110844416.0000\n",
      "Epoch 16/100\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 2.9274 - mse: 10146766821261312.0000 - val_loss: 5.5316 - val_mse: 7078867923632128.0000\n",
      "Epoch 17/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.8606 - mse: 9126616525438976.0000 - val_loss: 5.1130 - val_mse: 6046435631955968.0000\n",
      "Epoch 18/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.6993 - mse: 10026178098233344.0000 - val_loss: 6.0799 - val_mse: 6148504992874496.0000\n",
      "Epoch 19/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.7391 - mse: 8642231187537920.0000 - val_loss: 5.5518 - val_mse: 6299517116743680.0000\n",
      "Epoch 20/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.5822 - mse: 8666019937648640.0000 - val_loss: 5.7171 - val_mse: 6290844504031232.0000\n",
      "Epoch 21/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.5486 - mse: 8938710632497152.0000 - val_loss: 5.7765 - val_mse: 6031680271810560.0000\n",
      "Epoch 22/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.4611 - mse: 9654316608520192.0000 - val_loss: 5.7781 - val_mse: 5962706318262272.0000\n",
      "Epoch 23/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 2.4444 - mse: 8094184233762816.0000 - val_loss: 5.5706 - val_mse: 5869074957467648.0000\n",
      "Epoch 24/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.2710 - mse: 8936312967004160.0000 - val_loss: 5.5655 - val_mse: 5945577988685824.0000\n",
      "Epoch 25/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.3706 - mse: 8734362531004416.0000 - val_loss: 6.7128 - val_mse: 6945078081748992.0000\n",
      "Epoch 26/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.1915 - mse: 8607412961411072.0000 - val_loss: 5.9771 - val_mse: 6323236073635840.0000\n",
      "Epoch 27/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1730 - mse: 9640430979252224.0000 - val_loss: 5.5694 - val_mse: 5804002444836864.0000\n",
      "Epoch 28/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.1824 - mse: 9073751920476160.0000 - val_loss: 6.9210 - val_mse: 6024310107930624.0000\n",
      "Epoch 29/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0368 - mse: 9158481961549824.0000 - val_loss: 6.0656 - val_mse: 6090953504849920.0000\n",
      "Epoch 30/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 2.0832 - mse: 8936765549182976.0000 - val_loss: 5.6078 - val_mse: 5960045049151488.0000\n",
      "Epoch 31/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 2.0583 - mse: 8403912042217472.0000 - val_loss: 5.8324 - val_mse: 6292988766453760.0000\n",
      "Epoch 32/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.9333 - mse: 9054414903967744.0000 - val_loss: 5.6865 - val_mse: 6159254759145472.0000\n",
      "Epoch 33/100\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 1.9034 - mse: 8178578730516480.0000 - val_loss: 5.8502 - val_mse: 6025925552504832.0000\n",
      "Epoch 34/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.8398 - mse: 8908993753776128.0000 - val_loss: 6.4849 - val_mse: 5870564237377536.0000\n",
      "Epoch 35/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.8839 - mse: 8681691736440832.0000 - val_loss: 6.5019 - val_mse: 5943425136328704.0000\n",
      "Epoch 36/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.7852 - mse: 9818958811103232.0000 - val_loss: 6.2616 - val_mse: 5829714803425280.0000\n",
      "Epoch 37/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.8889 - mse: 9409578634575872.0000 - val_loss: 6.2902 - val_mse: 6078632854290432.0000\n",
      "Epoch 38/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.7272 - mse: 8136151432953856.0000 - val_loss: 5.7611 - val_mse: 5920605975085056.0000\n",
      "Epoch 39/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.7729 - mse: 9486809662750720.0000 - val_loss: 6.2962 - val_mse: 5796203321098240.0000\n",
      "Epoch 40/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.7305 - mse: 9779663081570304.0000 - val_loss: 5.8802 - val_mse: 6497059842555904.0000\n",
      "Epoch 41/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 1.6405 - mse: 7658697635397632.0000 - val_loss: 5.9553 - val_mse: 5862015104974848.0000\n",
      "Epoch 42/100\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 1.6306 - mse: 8413595045986304.0000 - val_loss: 6.7455 - val_mse: 6005408493731840.0000\n",
      "Epoch 43/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.6660 - mse: 11235531367120896.0000 - val_loss: 6.0025 - val_mse: 5842672719757312.0000\n",
      "Epoch 44/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.4825 - mse: 9128401084350464.0000 - val_loss: 5.9025 - val_mse: 5703808910884864.0000\n",
      "Epoch 45/100\n",
      "240/240 [==============================] - 3s 11ms/step - loss: 1.5027 - mse: 10653669598953472.0000 - val_loss: 6.0839 - val_mse: 5555156334673920.0000\n",
      "Epoch 46/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.4970 - mse: 9320765153345536.0000 - val_loss: 6.6031 - val_mse: 5514178051702784.0000\n",
      "Epoch 47/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.5072 - mse: 8807154173607936.0000 - val_loss: 6.0553 - val_mse: 6267756907331584.0000\n",
      "Epoch 48/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.5692 - mse: 9123834460372992.0000 - val_loss: 6.3984 - val_mse: 5987830266331136.0000\n",
      "Epoch 49/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.5297 - mse: 9775586083864576.0000 - val_loss: 6.1583 - val_mse: 5848098337193984.0000\n",
      "Epoch 50/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.5678 - mse: 8798101456289792.0000 - val_loss: 6.3385 - val_mse: 6290673779081216.0000\n",
      "Epoch 51/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.4244 - mse: 8394081398947840.0000 - val_loss: 6.9349 - val_mse: 6567573541879808.0000\n",
      "Epoch 52/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.3541 - mse: 8801173431648256.0000 - val_loss: 6.1692 - val_mse: 5997446161235968.0000\n",
      "Epoch 53/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.3593 - mse: 8555916840402944.0000 - val_loss: 6.5195 - val_mse: 5708315942191104.0000\n",
      "Epoch 54/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.3540 - mse: 8279818089005056.0000 - val_loss: 8.1054 - val_mse: 5916403886456832.0000\n",
      "Epoch 55/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.2733 - mse: 9786075467743232.0000 - val_loss: 5.6889 - val_mse: 5954586682589184.0000\n",
      "Epoch 56/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 1.2823 - mse: 8675460812636160.0000 - val_loss: 6.1383 - val_mse: 6163819772510208.0000\n",
      "Epoch 57/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.3754 - mse: 8178643691896832.0000 - val_loss: 6.9548 - val_mse: 5781127449018368.0000\n",
      "Epoch 58/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.2591 - mse: 8510349384876032.0000 - val_loss: 6.4062 - val_mse: 6388005791072256.0000\n",
      "Epoch 59/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.3402 - mse: 7931731390758912.0000 - val_loss: 5.9094 - val_mse: 6052826006421504.0000\n",
      "Epoch 60/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.3122 - mse: 8986809971245056.0000 - val_loss: 6.0633 - val_mse: 5982600606777344.0000\n",
      "Epoch 61/100\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 1.2259 - mse: 9670677212692480.0000 - val_loss: 6.2085 - val_mse: 5945387399512064.0000\n",
      "Epoch 62/100\n",
      "240/240 [==============================] - 2s 6ms/step - loss: 1.2115 - mse: 7905274929086464.0000 - val_loss: 6.4269 - val_mse: 5639347357351936.0000\n",
      "Epoch 63/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.3211 - mse: 8454215236059136.0000 - val_loss: 6.3675 - val_mse: 5977110564831232.0000\n",
      "Epoch 64/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.3815 - mse: 7847887723560960.0000 - val_loss: 6.7349 - val_mse: 5720357956747264.0000\n",
      "Epoch 65/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 1.1555 - mse: 7502778511392768.0000 - val_loss: 6.6758 - val_mse: 6189590113157120.0000\n",
      "Epoch 66/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 1.1182 - mse: 7506155429429248.0000 - val_loss: 6.3281 - val_mse: 6270113770635264.0000\n",
      "Epoch 67/100\n",
      "240/240 [==============================] - 1s 6ms/step - loss: 1.2468 - mse: 7123798650257408.0000 - val_loss: 7.1042 - val_mse: 5690163799785472.0000\n",
      "Epoch 68/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.1470 - mse: 6964220214116352.0000 - val_loss: 6.1037 - val_mse: 5695172805394432.0000\n",
      "Epoch 69/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.1071 - mse: 6821447985004544.0000 - val_loss: 6.4236 - val_mse: 5951848640937984.0000\n",
      "Epoch 70/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.1618 - mse: 6781133274480640.0000 - val_loss: 6.5398 - val_mse: 5874737334976512.0000\n",
      "Epoch 71/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.1704 - mse: 8053578002333696.0000 - val_loss: 6.4621 - val_mse: 5555214316732416.0000\n",
      "Epoch 72/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.0093 - mse: 7340216683593728.0000 - val_loss: 6.1421 - val_mse: 5785953381646336.0000\n",
      "Epoch 73/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.2276 - mse: 7012406525952000.0000 - val_loss: 7.5586 - val_mse: 6295084710494208.0000\n",
      "Epoch 74/100\n",
      "240/240 [==============================] - 2s 10ms/step - loss: 1.2671 - mse: 7970793044574208.0000 - val_loss: 6.8294 - val_mse: 5669117386293248.0000\n",
      "Epoch 75/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.0432 - mse: 7433867371741184.0000 - val_loss: 6.4784 - val_mse: 5878605489897472.0000\n",
      "Epoch 76/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.1022 - mse: 7155549732864000.0000 - val_loss: 6.0884 - val_mse: 6306748231057408.0000\n",
      "Epoch 77/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.0705 - mse: 8091389283794944.0000 - val_loss: 7.0235 - val_mse: 5826002341068800.0000\n",
      "Epoch 78/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.1105 - mse: 6621804483313664.0000 - val_loss: 7.2607 - val_mse: 5970802331615232.0000\n",
      "Epoch 79/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9732 - mse: 6229582164262912.0000 - val_loss: 6.6130 - val_mse: 5920287610634240.0000\n",
      "Epoch 80/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.0235 - mse: 6291166626578432.0000 - val_loss: 6.9967 - val_mse: 6496572900638720.0000\n",
      "Epoch 81/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.0894 - mse: 5852610737209344.0000 - val_loss: 6.1620 - val_mse: 6787791547531264.0000\n",
      "Epoch 82/100\n",
      "240/240 [==============================] - 2s 9ms/step - loss: 1.0657 - mse: 6612033432715264.0000 - val_loss: 6.2677 - val_mse: 5936260057137152.0000\n",
      "Epoch 83/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9158 - mse: 6081829383700480.0000 - val_loss: 6.9151 - val_mse: 6026750186225664.0000\n",
      "Epoch 84/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.1510 - mse: 5983740920594432.0000 - val_loss: 5.7915 - val_mse: 5744880609394688.0000\n",
      "Epoch 85/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.9479 - mse: 6727818234822656.0000 - val_loss: 6.0492 - val_mse: 6096018881904640.0000\n",
      "Epoch 86/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9116 - mse: 5879521391673344.0000 - val_loss: 5.7141 - val_mse: 5703972119642112.0000\n",
      "Epoch 87/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.1204 - mse: 5913068307480576.0000 - val_loss: 7.2983 - val_mse: 5710939093467136.0000\n",
      "Epoch 88/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9300 - mse: 5238674153275392.0000 - val_loss: 6.3721 - val_mse: 6070833193680896.0000\n",
      "Epoch 89/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9830 - mse: 5856656596402176.0000 - val_loss: 6.8480 - val_mse: 5676246495133696.0000\n",
      "Epoch 90/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.8630 - mse: 5933910173155328.0000 - val_loss: 7.1638 - val_mse: 5855412666499072.0000\n",
      "Epoch 91/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.8294 - mse: 5247533060194304.0000 - val_loss: 6.5528 - val_mse: 5867669966290944.0000\n",
      "Epoch 92/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.8764 - mse: 6957760583303168.0000 - val_loss: 6.3592 - val_mse: 6382066925043712.0000\n",
      "Epoch 93/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.9866 - mse: 5067105779056640.0000 - val_loss: 6.3134 - val_mse: 5877376055508992.0000\n",
      "Epoch 94/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 1.0440 - mse: 5522878581702656.0000 - val_loss: 6.1889 - val_mse: 5955710353408000.0000\n",
      "Epoch 95/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 1.0316 - mse: 6889939291602944.0000 - val_loss: 6.8186 - val_mse: 6524690440912896.0000\n",
      "Epoch 96/100\n",
      "240/240 [==============================] - 2s 7ms/step - loss: 0.8576 - mse: 5729584083369984.0000 - val_loss: 6.2398 - val_mse: 6032405047541760.0000\n",
      "Epoch 97/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.9171 - mse: 6462170212597760.0000 - val_loss: 6.3839 - val_mse: 6096856937398272.0000\n",
      "Epoch 98/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.8770 - mse: 5956238634385408.0000 - val_loss: 6.5783 - val_mse: 5878077745790976.0000\n",
      "Epoch 99/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.9237 - mse: 6004292339105792.0000 - val_loss: 6.4088 - val_mse: 5804894724292608.0000\n",
      "Epoch 100/100\n",
      "240/240 [==============================] - 2s 8ms/step - loss: 0.8762 - mse: 6131344451043328.0000 - val_loss: 6.6668 - val_mse: 5893703910555648.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.values, y_train.values, validation_data=(X_test.values, y_test.values), epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 0s 3ms/step - loss: 6.6668 - mse: 5893703910555648.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[6.666798114776611, 5893703910555648.0]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[99652940.0,\n",
       " 2645883.8,\n",
       " 40856212.0,\n",
       " 48840.242,\n",
       " 9353804.0,\n",
       " 47456350.0,\n",
       " 4797987.5,\n",
       " 29444856.0,\n",
       " 58760828.0,\n",
       " 400364160.0,\n",
       " 2826854.2,\n",
       " 232048.02,\n",
       " 8505950.0,\n",
       " 134316.52,\n",
       " 45891044.0,\n",
       " 38061.58,\n",
       " 20903032.0,\n",
       " 268950000.0,\n",
       " 63756640.0,\n",
       " 875164400.0,\n",
       " 8360789.0,\n",
       " 72633990.0,\n",
       " 17261.773,\n",
       " 7915370.0,\n",
       " 134608.27,\n",
       " 43141920.0,\n",
       " 1409905.0,\n",
       " 122215810.0,\n",
       " 84215.195,\n",
       " 59455976.0,\n",
       " 13491682.0,\n",
       " 26317124.0,\n",
       " 813158.3,\n",
       " 319442.9,\n",
       " 1927291.2,\n",
       " 26366844.0,\n",
       " 144406290.0,\n",
       " 103547440.0,\n",
       " 374553.44,\n",
       " 6830001.5,\n",
       " 4906611.0,\n",
       " 8409473.0,\n",
       " 7705404.0,\n",
       " 3364841.0,\n",
       " 467028100.0,\n",
       " 594450.6,\n",
       " 16902408.0,\n",
       " 3513949.0,\n",
       " 79686960.0,\n",
       " 81175520.0,\n",
       " 86237.18,\n",
       " 33829430.0,\n",
       " 397231.12,\n",
       " 1166287.2,\n",
       " 48495884.0,\n",
       " 31735.691,\n",
       " 108041680.0,\n",
       " 586551200.0,\n",
       " 27.196936,\n",
       " 58879640.0,\n",
       " 79417640.0,\n",
       " 34580656.0,\n",
       " 11928641.0,\n",
       " 135287340.0,\n",
       " 53300990.0,\n",
       " 149345180.0,\n",
       " 11769642.0,\n",
       " 23619522.0,\n",
       " 369546560.0,\n",
       " 2020619.0,\n",
       " 1388324.0,\n",
       " 694024300.0,\n",
       " 5594496.0,\n",
       " 19527.666,\n",
       " 45857108.0,\n",
       " 125108830.0,\n",
       " 401419.62,\n",
       " 39404384.0,\n",
       " 84818620.0,\n",
       " 74198100.0,\n",
       " 7818063.0,\n",
       " 21070746.0,\n",
       " 5393162.5,\n",
       " 5762474.0,\n",
       " 62843664.0,\n",
       " 38312436.0,\n",
       " 35680.863,\n",
       " 368984.16,\n",
       " 1332847.8,\n",
       " 47683732.0,\n",
       " 54967388.0,\n",
       " 14612806.0,\n",
       " 318204480.0,\n",
       " 128163304.0,\n",
       " 41710140.0,\n",
       " 6142460.0,\n",
       " 1051738750.0,\n",
       " 38849548.0,\n",
       " 96031190.0,\n",
       " 75707440.0,\n",
       " 14288159.0,\n",
       " 25162390.0,\n",
       " 6414194.0,\n",
       " 8475404.0,\n",
       " 192746080.0,\n",
       " 124491680.0,\n",
       " 14090164.0,\n",
       " 11663144.0,\n",
       " 61674640.0,\n",
       " 466582500.0,\n",
       " 33184190.0,\n",
       " 1168908.4,\n",
       " 36222428.0,\n",
       " 19971472.0,\n",
       " 5280966.5,\n",
       " 5324410.0,\n",
       " 3510432.2,\n",
       " 16636042.0,\n",
       " 246444180.0,\n",
       " 124114020.0,\n",
       " 525782.56,\n",
       " 8150323.0,\n",
       " 3676256.2,\n",
       " 2867883.0,\n",
       " 101271.695,\n",
       " 67234810.0,\n",
       " 2348528.5,\n",
       " 29855596.0,\n",
       " 103222104.0,\n",
       " 33371768.0,\n",
       " 19002940.0,\n",
       " 437608.1,\n",
       " 5183697.5,\n",
       " 9144412.0,\n",
       " 603718.3,\n",
       " 2389415.5,\n",
       " 103667650.0,\n",
       " 786918.94,\n",
       " 53802350.0,\n",
       " 70573620.0,\n",
       " 35012924.0,\n",
       " 8354466.0,\n",
       " 257964750.0,\n",
       " 252778.23,\n",
       " 5508608.0,\n",
       " 28.080875,\n",
       " 65704110.0,\n",
       " 409414.56,\n",
       " 175505820.0,\n",
       " 27708930.0,\n",
       " 3448944.8,\n",
       " 1123358.4,\n",
       " 47683930.0,\n",
       " 15796617.0,\n",
       " 640539.5,\n",
       " 3024260.8,\n",
       " 13278306.0,\n",
       " 109810940.0,\n",
       " 1641337.8,\n",
       " 14963239.0,\n",
       " 445660.06,\n",
       " 7155671.0,\n",
       " 70575096.0,\n",
       " 4516947.5,\n",
       " 2094910.2,\n",
       " 558006.0,\n",
       " 49723824.0,\n",
       " 252484.14,\n",
       " 52054628.0,\n",
       " 5419103.0,\n",
       " 21386974.0,\n",
       " 11887776.0,\n",
       " 1224277.8,\n",
       " 2089838.0,\n",
       " 30999834.0,\n",
       " 863138.75,\n",
       " 26291642.0,\n",
       " 4255852.0,\n",
       " 7524108.0,\n",
       " 15483468.0,\n",
       " 353023.94,\n",
       " 149543170.0,\n",
       " 20576706.0,\n",
       " 28892204.0,\n",
       " 81914670.0,\n",
       " 15649794.0,\n",
       " 2425926.8,\n",
       " 9958756.0,\n",
       " 115480740.0,\n",
       " 31644580.0,\n",
       " 19713240.0,\n",
       " 30177124.0,\n",
       " 108188390.0,\n",
       " 17040556.0,\n",
       " 1084280.8,\n",
       " 21653694.0,\n",
       " 774861.56,\n",
       " 98511600.0,\n",
       " 305495940.0,\n",
       " 38668740.0,\n",
       " 82203440.0,\n",
       " 82.20201,\n",
       " 4769384.0,\n",
       " 1120467.0,\n",
       " 7327106.0,\n",
       " 8755049.0,\n",
       " 1974998.5,\n",
       " 458947.6,\n",
       " 15333788.0,\n",
       " 490068300.0,\n",
       " 7341832.0,\n",
       " 45177996.0,\n",
       " 83875170.0,\n",
       " 9386713.0,\n",
       " 900765.8,\n",
       " 26347332.0,\n",
       " 375675550.0,\n",
       " 17012120.0,\n",
       " 41967760.0,\n",
       " 2121378.0,\n",
       " 21427492.0,\n",
       " 5664576.0,\n",
       " 37770090.0,\n",
       " 9.461143,\n",
       " 2555767.0,\n",
       " 11763551.0,\n",
       " 48824988.0,\n",
       " 249085820.0,\n",
       " 146847680.0,\n",
       " 11889952.0,\n",
       " 88919920.0,\n",
       " 8514381.0,\n",
       " 4887480.0,\n",
       " 570636.25,\n",
       " 317729.94,\n",
       " 18881.281,\n",
       " 24316216.0,\n",
       " 1296677.0,\n",
       " 38972.387,\n",
       " 371175680.0,\n",
       " 3797469.5,\n",
       " 7153937.0,\n",
       " 23550372.0,\n",
       " nan,\n",
       " 33736652.0,\n",
       " 5001027.0,\n",
       " 53054316.0,\n",
       " 1522464.9,\n",
       " 30676354.0,\n",
       " 507156740.0,\n",
       " 2997491.0,\n",
       " 1872268.2,\n",
       " 32908148.0,\n",
       " 159386.56,\n",
       " 302533.7,\n",
       " 40753870.0,\n",
       " 44593430.0,\n",
       " 70526770.0,\n",
       " 15642166.0,\n",
       " 199136.9,\n",
       " 514354240.0,\n",
       " 13322959.0,\n",
       " 19827204.0,\n",
       " 112425.98,\n",
       " 193419.61,\n",
       " 620778.75,\n",
       " 13159909.0,\n",
       " 36464.297,\n",
       " 2808502.8,\n",
       " 118514136.0,\n",
       " 25889624.0,\n",
       " 894645.3,\n",
       " 7892297.0,\n",
       " 422599360.0,\n",
       " 19355348.0,\n",
       " 4255985.0,\n",
       " 74836190.0,\n",
       " 8751404.0,\n",
       " 6807126.5,\n",
       " 283105280.0,\n",
       " 268810.47,\n",
       " 10860029.0,\n",
       " 480779780.0,\n",
       " 34356490.0,\n",
       " 31316880.0,\n",
       " 203220.92,\n",
       " 896395.56,\n",
       " 22620118.0,\n",
       " 55271070.0,\n",
       " 89075704.0,\n",
       " 16946540.0,\n",
       " 103663210.0,\n",
       " 21415658.0,\n",
       " 3478810.0,\n",
       " 3561588.5,\n",
       " 7177722.5,\n",
       " 3839977.5,\n",
       " 67109576.0,\n",
       " 5676764.0,\n",
       " 9722839.0,\n",
       " 158623.11,\n",
       " 4862126.5,\n",
       " 179071.8,\n",
       " 13930355.0,\n",
       " 36029230.0,\n",
       " 222984.73,\n",
       " 30910632.0,\n",
       " 10565404.0,\n",
       " 6056979.0,\n",
       " 17152884.0,\n",
       " 6647388.5,\n",
       " 1059724.4,\n",
       " 20873910.0,\n",
       " 61864470.0,\n",
       " 195026940.0,\n",
       " 20419332.0,\n",
       " 7153420.5,\n",
       " 2100322.8,\n",
       " 9399886.0,\n",
       " 4232860.0,\n",
       " 15428706.0,\n",
       " 2388899.0,\n",
       " 79921910.0,\n",
       " 3417573.8,\n",
       " 142168100.0,\n",
       " 165422620.0,\n",
       " 47171252.0,\n",
       " 4326842.5,\n",
       " 24376802.0,\n",
       " 125359590.0,\n",
       " 20287.436,\n",
       " 11589545.0,\n",
       " 320922000.0,\n",
       " 7161948.5,\n",
       " 56548256.0,\n",
       " 7899307.5,\n",
       " 171540.39,\n",
       " 51269070.0,\n",
       " 1794872.9,\n",
       " 15311084.0,\n",
       " 5912988.5,\n",
       " 11475983.0,\n",
       " 44882456.0,\n",
       " 3264460.0,\n",
       " 15183673.0,\n",
       " 38889060.0,\n",
       " 362654.75,\n",
       " 39699980.0,\n",
       " 41272772.0,\n",
       " 227644720.0,\n",
       " 18285720.0,\n",
       " 3567374.5,\n",
       " 5721135.5,\n",
       " 2709.672,\n",
       " 7636652.0,\n",
       " 107729730.0,\n",
       " 51242.035,\n",
       " 13101839.0,\n",
       " 28107314.0,\n",
       " 16043288.0,\n",
       " 68501304.0,\n",
       " 5807304.5,\n",
       " 1281191.0,\n",
       " 9156844.0,\n",
       " 623295.06,\n",
       " 174876500.0,\n",
       " 83908590.0,\n",
       " 6522429.0,\n",
       " 28461248.0,\n",
       " 77528340.0,\n",
       " 32374636.0,\n",
       " 64179624.0,\n",
       " 46845520.0,\n",
       " 20943780.0,\n",
       " 69235580.0,\n",
       " 34552700.0,\n",
       " 87878160.0,\n",
       " 27204336.0,\n",
       " 171539200.0,\n",
       " 15311976.0,\n",
       " 3502799.8,\n",
       " 314372.12,\n",
       " 383884.84,\n",
       " 40460244.0,\n",
       " 136092960.0,\n",
       " 515881.3,\n",
       " 22231102.0,\n",
       " 251862850.0,\n",
       " 847459500.0,\n",
       " 50831230.0,\n",
       " 3379801.5,\n",
       " 35294630.0,\n",
       " 763385.3,\n",
       " 138271150.0,\n",
       " 99355520.0,\n",
       " 411449.7,\n",
       " 300892.38,\n",
       " 286915360.0,\n",
       " 110303650.0,\n",
       " 12139970.0,\n",
       " 6640711.5,\n",
       " 819545.56,\n",
       " 216635680.0,\n",
       " 29143780.0,\n",
       " 11636961.0,\n",
       " 144885540.0,\n",
       " 260481400.0,\n",
       " 51502628.0,\n",
       " 512303.1,\n",
       " 46304864.0,\n",
       " 106905064.0,\n",
       " 3702300.5,\n",
       " 20011490.0,\n",
       " 2951204.5,\n",
       " 4009355.0,\n",
       " 99627180.0,\n",
       " 75264100.0,\n",
       " 22235628.0,\n",
       " 289274430.0,\n",
       " 660632.44,\n",
       " 22906988.0,\n",
       " 141702.95,\n",
       " 684318300.0,\n",
       " 390695.03,\n",
       " 4559532.0,\n",
       " 70304300.0,\n",
       " 26749110.0,\n",
       " 12236221.0,\n",
       " 122219460.0,\n",
       " 772520000.0,\n",
       " 16973324.0,\n",
       " 15934494.0,\n",
       " 1933560.0,\n",
       " 11856362.0,\n",
       " 309450940.0,\n",
       " 219827180.0,\n",
       " 17492376.0,\n",
       " 69134610.0,\n",
       " 12688702.0,\n",
       " 13251234.0,\n",
       " 28320044.0,\n",
       " 673868.5,\n",
       " 4898987.0,\n",
       " 2362993.0,\n",
       " 63080430.0,\n",
       " 1337241.8,\n",
       " 3204952.2,\n",
       " 53450388.0,\n",
       " 3643540.0,\n",
       " 32902016.0,\n",
       " 9187224.0,\n",
       " 18295484.0,\n",
       " 29046258.0,\n",
       " 46288130.0,\n",
       " 1360557.8,\n",
       " 105266300.0,\n",
       " 2781653.8,\n",
       " 1104942.8,\n",
       " 771022850.0,\n",
       " 10669574.0,\n",
       " 226958.7,\n",
       " 1475211.9,\n",
       " 89020150.0,\n",
       " 1147814.6,\n",
       " 11396676.0,\n",
       " 8843619.0,\n",
       " 56357560.0,\n",
       " 46263316.0,\n",
       " 5622434.0,\n",
       " 49271.39,\n",
       " 22132236.0,\n",
       " 4807159.5,\n",
       " 46561620.0,\n",
       " 12209090.0,\n",
       " 350093630.0,\n",
       " 9159399.0,\n",
       " 42640384.0,\n",
       " 10337365.0,\n",
       " 268520640.0,\n",
       " 14154387.0,\n",
       " 10637528.0,\n",
       " 1845202.0,\n",
       " 2601727.2,\n",
       " 1002222.44,\n",
       " 104332180.0,\n",
       " 67283930.0,\n",
       " 56989430.0,\n",
       " 83441180.0,\n",
       " 47740236.0,\n",
       " 1975928.5,\n",
       " 9513729.0,\n",
       " 5561890.5,\n",
       " 40015320.0,\n",
       " 21862112.0,\n",
       " 120021980.0,\n",
       " 16416031.0,\n",
       " 47545336.0,\n",
       " 5765272.0,\n",
       " 3141304.8,\n",
       " 13999.91,\n",
       " 99413050.0,\n",
       " 44718650.0,\n",
       " 35810970.0,\n",
       " 6436163.0,\n",
       " 49818.54,\n",
       " 119483660.0,\n",
       " 410161800.0,\n",
       " 23131122.0,\n",
       " 273609.53,\n",
       " 2172619.8,\n",
       " 24934994.0,\n",
       " 208193400.0,\n",
       " 3255645.5,\n",
       " 10792632.0,\n",
       " 585570.0,\n",
       " 5096724.5,\n",
       " 746210800.0,\n",
       " 29881902.0,\n",
       " 30231652.0,\n",
       " 12453903.0,\n",
       " 26412820.0,\n",
       " 42395290.0,\n",
       " 20380232.0,\n",
       " 105351020.0,\n",
       " 139691490.0,\n",
       " 34904052.0,\n",
       " 55091360.0,\n",
       " 8805114.0,\n",
       " 558847900.0,\n",
       " 36040430.0,\n",
       " 53122536.0,\n",
       " 111696660.0,\n",
       " 7026446.0,\n",
       " 22621670.0,\n",
       " 302005950.0,\n",
       " 725031.9,\n",
       " 104467190.0,\n",
       " 25857092.0,\n",
       " 1825279.8,\n",
       " 12187345.0,\n",
       " 26164184.0,\n",
       " 18991326.0,\n",
       " 4345157.0,\n",
       " 103902856.0,\n",
       " 162309.52,\n",
       " 1293922.5,\n",
       " 208437380.0,\n",
       " 551088100.0,\n",
       " 773191.1,\n",
       " 120060860.0,\n",
       " 167446910.0,\n",
       " 65875536.0,\n",
       " 34513548.0,\n",
       " 187100260.0,\n",
       " 128398060.0,\n",
       " 35208828.0,\n",
       " 21075922.0,\n",
       " 154231840.0,\n",
       " 49701880.0,\n",
       " 19.788792,\n",
       " 88937080.0,\n",
       " 24262544.0,\n",
       " 10243752.0,\n",
       " 1923027.8,\n",
       " 693133.2,\n",
       " 108079416.0,\n",
       " 5475477.5,\n",
       " 3429504.8,\n",
       " 50056030.0,\n",
       " 1820545.8,\n",
       " 7672220.5,\n",
       " 127951830.0,\n",
       " 1166811.0,\n",
       " 8471425.0,\n",
       " 2641190.0,\n",
       " 12068214.0,\n",
       " 25701186.0,\n",
       " 10492249.0,\n",
       " 8537494.0,\n",
       " 78248980.0,\n",
       " 10507751.0,\n",
       " 116261624.0,\n",
       " 703403.75,\n",
       " 4530512.0,\n",
       " 36384430.0,\n",
       " 23826060.0,\n",
       " 57397756.0,\n",
       " 689767.44,\n",
       " 11388726.0,\n",
       " 63006890.0,\n",
       " 541755460.0,\n",
       " 2883401.5,\n",
       " 110274.61,\n",
       " 4651523.0,\n",
       " 29719130.0,\n",
       " 2473140.5,\n",
       " 19487726.0,\n",
       " 63071348.0,\n",
       " 6798945.0,\n",
       " 15064154.0,\n",
       " 257157.95,\n",
       " 1720298.5,\n",
       " 8879156.0,\n",
       " 5722903.5,\n",
       " 56800276.0,\n",
       " 3395968.5,\n",
       " 40750960.0,\n",
       " 118859090.0,\n",
       " 12203602.0,\n",
       " 65112130.0,\n",
       " 918436.3,\n",
       " 2390974.0,\n",
       " 326782.3,\n",
       " 53420750.0,\n",
       " 32060196.0,\n",
       " 45.735153,\n",
       " 28998834.0,\n",
       " 30056312.0,\n",
       " 1096285.4,\n",
       " 171851940.0,\n",
       " 211693600.0,\n",
       " 255100160.0,\n",
       " 139536290.0,\n",
       " 450495.4,\n",
       " 4869673.0,\n",
       " 24827688.0,\n",
       " 6742683.0,\n",
       " 359793000.0,\n",
       " 140474.52,\n",
       " 290203.75,\n",
       " 206594990.0,\n",
       " 41374880.0,\n",
       " 60217780.0,\n",
       " 1210837.2,\n",
       " 4540407.0,\n",
       " 28429404.0,\n",
       " 17831544.0,\n",
       " 24432564.0,\n",
       " 100736610.0,\n",
       " 567639940.0,\n",
       " 34073.953,\n",
       " 3245429.5,\n",
       " 77275630.0,\n",
       " 55958.145,\n",
       " 41031636.0,\n",
       " 2901596.8,\n",
       " 21812602.0,\n",
       " 1254752.0,\n",
       " 2992414.8,\n",
       " 13476798.0,\n",
       " 541106370.0,\n",
       " 22147296.0,\n",
       " 251424700.0,\n",
       " 3323487.8,\n",
       " 21171190.0,\n",
       " 2738208.5,\n",
       " 40860.117,\n",
       " 12910930.0,\n",
       " 152040670.0,\n",
       " 278827900.0,\n",
       " 4998033.0,\n",
       " 7933023.0,\n",
       " 502367840.0,\n",
       " 2133389.5,\n",
       " 1608399.5,\n",
       " 13782496.0,\n",
       " 110591790.0,\n",
       " 58940364.0,\n",
       " 3089297.0,\n",
       " 5363777.0,\n",
       " 25173800.0,\n",
       " 7983562.0,\n",
       " 178804780.0,\n",
       " 12306462.0,\n",
       " 471359420.0,\n",
       " 155120480.0,\n",
       " 5607339.0,\n",
       " 17160916.0,\n",
       " 27644794.0,\n",
       " 2523468.5,\n",
       " 1745676.5,\n",
       " 160443200.0,\n",
       " 13680787.0,\n",
       " 29905100.0,\n",
       " 113732700.0,\n",
       " 12798868.0,\n",
       " 221791260.0,\n",
       " 13198861.0,\n",
       " 26737.207,\n",
       " 76253300.0,\n",
       " 7442149.0,\n",
       " 8906.784,\n",
       " 58501100.0,\n",
       " 80409330.0,\n",
       " 16038768.0,\n",
       " 39519756.0,\n",
       " 26632804.0,\n",
       " 76677650.0,\n",
       " 21998490.0,\n",
       " 77668170.0,\n",
       " 16776388.0,\n",
       " 1132698.0,\n",
       " 54212350.0,\n",
       " 148828600.0,\n",
       " 8565073.0,\n",
       " 71503200.0,\n",
       " 296272.72,\n",
       " 3889400.5,\n",
       " 308898430.0,\n",
       " 38608636.0,\n",
       " 7985920.0,\n",
       " 57813204.0,\n",
       " 40506270.0,\n",
       " 21505.434,\n",
       " 35968044.0,\n",
       " 7987449.5,\n",
       " 725537.06,\n",
       " 18816952.0,\n",
       " 47170200.0,\n",
       " 16244308.0,\n",
       " 170569.27,\n",
       " 161859970.0,\n",
       " 123441.61,\n",
       " 3018115.2,\n",
       " 80647230.0,\n",
       " 29234906.0,\n",
       " 273542660.0,\n",
       " 97693576.0,\n",
       " 26276336.0,\n",
       " 1100183.1,\n",
       " 71958870.0,\n",
       " 52183.656,\n",
       " 156675940.0,\n",
       " 563889900.0,\n",
       " 11685652.0,\n",
       " 19303202.0,\n",
       " 21258580.0,\n",
       " 2430413.8,\n",
       " 1195777.9,\n",
       " 10245888.0,\n",
       " 6117039.5,\n",
       " 79176620.0,\n",
       " 32920740.0,\n",
       " 211499140.0,\n",
       " 19401888.0,\n",
       " 60702136.0,\n",
       " 957.9261,\n",
       " 2189753.5,\n",
       " 8218703.5,\n",
       " 271097.38,\n",
       " 19149318.0,\n",
       " 4316418.5,\n",
       " 14191775.0,\n",
       " 21384028.0,\n",
       " 7607473.0,\n",
       " 916254.56,\n",
       " 394997540.0,\n",
       " 175827420.0,\n",
       " 7402885.0,\n",
       " 332669150.0,\n",
       " 28091248.0,\n",
       " 346400450.0,\n",
       " 5143520.0,\n",
       " 26085324.0,\n",
       " 6445778.0,\n",
       " 5673776.5,\n",
       " 14800972.0,\n",
       " 26440318.0,\n",
       " 399445.75,\n",
       " 730727.4,\n",
       " 50393880.0,\n",
       " 49936216.0,\n",
       " 11579122.0,\n",
       " 3552158.5,\n",
       " 10519808.0,\n",
       " 37023810.0,\n",
       " 1780426.6,\n",
       " 89274.125,\n",
       " 31840592.0,\n",
       " 150.99425,\n",
       " 3098670.2,\n",
       " 12688682.0,\n",
       " 3007424.5,\n",
       " 664977.06,\n",
       " 392593920.0,\n",
       " 18827304.0,\n",
       " 210471740.0,\n",
       " 942046340.0,\n",
       " 53587736.0,\n",
       " 5373762.0,\n",
       " 47927092.0,\n",
       " 304709.25,\n",
       " 560286.2,\n",
       " 19.368246,\n",
       " 270983100.0,\n",
       " 7994642.0,\n",
       " 13298356.0,\n",
       " 35252324.0,\n",
       " 3544945.0,\n",
       " 144079.38,\n",
       " 67465870.0,\n",
       " 213466.34,\n",
       " 5362641.5,\n",
       " 31738.477,\n",
       " 28006.088,\n",
       " 135702050.0,\n",
       " 190822.17,\n",
       " 470629.75,\n",
       " 43387220.0,\n",
       " 10591194.0,\n",
       " 36992524.0,\n",
       " 1292991.5,\n",
       " 467981.8,\n",
       " 558682.3,\n",
       " 14397432.0,\n",
       " 71548210.0,\n",
       " 84796590.0,\n",
       " 7712672.0,\n",
       " 28111978.0,\n",
       " 112115330.0,\n",
       " 21696992.0,\n",
       " 11735300.0,\n",
       " 124319.62,\n",
       " 901195.7,\n",
       " 26456564.0,\n",
       " 114993490.0,\n",
       " 75519850.0,\n",
       " 11940069.0,\n",
       " 89335.36,\n",
       " 24158844.0,\n",
       " 21325.797,\n",
       " 175694370.0,\n",
       " 12668640.0,\n",
       " 37679892.0,\n",
       " 5643240.0,\n",
       " 4560134.5,\n",
       " 8107526.5,\n",
       " 90521336.0,\n",
       " 128879.16,\n",
       " 66692770.0,\n",
       " 2727743.0,\n",
       " 10927617.0,\n",
       " 312319.8,\n",
       " 73504.66,\n",
       " 10871.463,\n",
       " 887632.9,\n",
       " 49256.5,\n",
       " 991774.94,\n",
       " 95570850.0,\n",
       " 7027826.0,\n",
       " 42275310.0,\n",
       " 2718267.8,\n",
       " 189325250.0,\n",
       " 485879.44,\n",
       " 6388294.0,\n",
       " 14497153.0,\n",
       " 813690750.0,\n",
       " 132400.2,\n",
       " 4277767.0,\n",
       " 8301061.0,\n",
       " 61541576.0,\n",
       " 19459452.0,\n",
       " 104459920.0,\n",
       " 2498941.5,\n",
       " 46912710.0,\n",
       " 17460972.0,\n",
       " 75272320.0,\n",
       " 26789110.0,\n",
       " 89711940.0,\n",
       " 125299500.0,\n",
       " 765374900.0,\n",
       " 1112307.1,\n",
       " 32029714.0,\n",
       " 2521036.0,\n",
       " 30416090.0,\n",
       " 1360902.0,\n",
       " 21789856.0,\n",
       " 69551256.0,\n",
       " 276590530.0,\n",
       " 3392402.8,\n",
       " 29436.227,\n",
       " 6766333.5,\n",
       " 1356909.4,\n",
       " 124185680.0,\n",
       " 20084020.0,\n",
       " 47162104.0,\n",
       " 10811520.0,\n",
       " 11879197.0,\n",
       " 56007730.0,\n",
       " 120947016.0,\n",
       " 3759591.0,\n",
       " 61072580.0,\n",
       " 399546600.0,\n",
       " 5741230.5,\n",
       " 15125204.0,\n",
       " 608656.2,\n",
       " 8571507.0,\n",
       " 13843893.0,\n",
       " 795042940.0,\n",
       " 64543180.0,\n",
       " 11129181.0,\n",
       " 3054611.8,\n",
       " 16784536.0,\n",
       " 4270678.0,\n",
       " 18663824.0,\n",
       " 14432447.0,\n",
       " 5219385.0,\n",
       " 8986460.0,\n",
       " 544.3605,\n",
       " 52078464.0,\n",
       " 4307925.0,\n",
       " 27935026.0,\n",
       " 114269680.0,\n",
       " 41468460.0,\n",
       " 323914620.0,\n",
       " 240188.61,\n",
       " 3702314.8,\n",
       " 24788824.0,\n",
       " 21956544.0,\n",
       " 115162740.0,\n",
       " 31430.594,\n",
       " 32819632.0,\n",
       " 67550060.0,\n",
       " 21938332.0,\n",
       " 230112380.0,\n",
       " 2677295.2,\n",
       " 106172610.0,\n",
       " 128916220.0,\n",
       " 32715832.0,\n",
       " 2484612.0,\n",
       " 20789954.0,\n",
       " 10482888.0,\n",
       " 29857016.0,\n",
       " 81264740.0,\n",
       " 5571.7407,\n",
       " 1772411.5,\n",
       " 258737700.0,\n",
       " 13850191.0,\n",
       " 14221260.0,\n",
       " 2667811.8,\n",
       " 23644978.0,\n",
       " 296946980.0,\n",
       " 829156350.0,\n",
       " 8461541.0,\n",
       " 244563.02,\n",
       " 2783435.8,\n",
       " 108443400.0,\n",
       " 2728801.8,\n",
       " 28587784.0,\n",
       " 586856.0,\n",
       " 21556454.0,\n",
       " 81474960.0,\n",
       " 110842730.0,\n",
       " 566619200.0,\n",
       " 39825850.0,\n",
       " 20324352.0,\n",
       " 436334.56,\n",
       " 5129677.5,\n",
       " 8898936.0,\n",
       " 3150804.0,\n",
       " 21011320.0,\n",
       " 702276.0,\n",
       " 1920589.6,\n",
       " 789138500.0,\n",
       " 113840340.0,\n",
       " 2649527.8,\n",
       " 480294620.0,\n",
       " 10016898.0,\n",
       " 680036.2,\n",
       " 18324862.0,\n",
       " 27146444.0,\n",
       " 79126110.0,\n",
       " 40427750.0,\n",
       " 243544.72,\n",
       " 126109250.0,\n",
       " 37798516.0,\n",
       " 64508710.0,\n",
       " 156330720.0,\n",
       " 11173729.0,\n",
       " 723155.44,\n",
       " 3509014.0,\n",
       " 10495504.0,\n",
       " 51520744.0,\n",
       " 198929550.0,\n",
       " 1610878.2,\n",
       " 945924200.0,\n",
       " 35477172.0,\n",
       " 22126888.0,\n",
       " 44133480.0,\n",
       " 58490076.0,\n",
       " 104452.73,\n",
       " 1296668.2,\n",
       " 8215413.0,\n",
       " 18699068.0,\n",
       " 15136853.0,\n",
       " 29975768.0,\n",
       " 1199843.5,\n",
       " 38740904.0,\n",
       " 45572390.0,\n",
       " 217449150.0,\n",
       " ...]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_final_df.values)\n",
    "predictions = [prediction[0] for prediction in predictions]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3001</td>\n",
       "      <td>9.965294e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3002</td>\n",
       "      <td>2.645884e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3003</td>\n",
       "      <td>4.085621e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3004</td>\n",
       "      <td>4.884024e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3005</td>\n",
       "      <td>9.353804e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4393</th>\n",
       "      <td>7394</td>\n",
       "      <td>6.719358e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4394</th>\n",
       "      <td>7395</td>\n",
       "      <td>1.321240e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4395</th>\n",
       "      <td>7396</td>\n",
       "      <td>2.312267e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4396</th>\n",
       "      <td>7397</td>\n",
       "      <td>6.522742e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4397</th>\n",
       "      <td>7398</td>\n",
       "      <td>8.130917e+04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4398 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id       revenue\n",
       "0     3001  9.965294e+07\n",
       "1     3002  2.645884e+06\n",
       "2     3003  4.085621e+07\n",
       "3     3004  4.884024e+04\n",
       "4     3005  9.353804e+06\n",
       "...    ...           ...\n",
       "4393  7394  6.719358e+07\n",
       "4394  7395  1.321240e+07\n",
       "4395  7396  2.312267e+07\n",
       "4396  7397  6.522742e+07\n",
       "4397  7398  8.130917e+04\n",
       "\n",
       "[4398 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_test_df = test_df = pd.read_csv(\"test.csv\")\n",
    "submission_df = pd.DataFrame({\"id\" : original_test_df.id, \"revenue\" : predictions})\n",
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
